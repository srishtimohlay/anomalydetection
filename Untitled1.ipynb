{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b6e38c",
   "metadata": {},
   "source": [
    "# Step 1: Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52eb6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "#libraries for visualizing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import missingno\n",
    "\n",
    "#libraries for preprocessing and algorithms\n",
    "from sklearn.impute import SimpleImputer\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.api import VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c7da8c",
   "metadata": {},
   "source": [
    "# Step 2: Collecting the Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8ce6c-d1fe-43ee-be52-4e8c5976ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting the data\n",
    "df= pd.read_csv('data.csv')\n",
    "print(df.columns)\n",
    "print(df.index)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec8c98-897e-4f23-b1a5-60432c1d9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general overview\n",
    "plt.rcParams['figure.dpi']=600\n",
    "fig=plt.figure(figsize=(2,0.1), facecolor= '#f6f5f5')\n",
    "gs= fig.add_gridspec(1,1)\n",
    "gs.update(wspace=0, hspace=0)\n",
    "\n",
    "background_color= \"#f6f5f5\"\n",
    "\n",
    "ax0= fig.add_subplot(gs[0,0])\n",
    "ax0.set_facecolor(background_color)\n",
    "for s in ['top', 'left', 'right', 'bottom']:\n",
    "    ax0.spines[s].set_visible(False)\n",
    "\n",
    "ax0.set_xticks([])\n",
    "ax0.set_yticks([])\n",
    "ax0.grid(which='major', axis='y', zorder=0, color='#EEEEEE')\n",
    "ax0.text(0, 0.79, '377719', color='#A8F712', fontsize=20, ha='center', weight='bold', va='bottom')\n",
    "ax0.text(0, 0, 'Number of rows', color='#bbd092', fontsize=6, ha='center', va='top', weight='bold')\n",
    "ax0.text(0.9, 0.79, '7', color='#A8F712', fontsize=20, ha='center', weight='bold', va='bottom')\n",
    "ax0.text(0.9, 0, 'Number of columns', color='#bbd092', fontsize=6, ha='center', va='top', weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ff1fe5",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b64f8-8126-4ba3-93f0-c239654b3745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538c4297-28d3-4249-83c5-941bea9d7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all are object type, coverting to float will increase accuracy while we wil feed our data into ML algorithms.\n",
    "\n",
    "df['Cyclone_Inlet_Gas_Temp'] = pd.to_numeric(df['Cyclone_Inlet_Gas_Temp'], errors='coerce')\n",
    "df['Cyclone_Material_Temp'] = pd.to_numeric(df['Cyclone_Material_Temp'], errors='coerce')\n",
    "df['Cyclone_Outlet_Gas_draft'] = pd.to_numeric(df['Cyclone_Outlet_Gas_draft'], errors='coerce')\n",
    "df['Cyclone_cone_draft'] = pd.to_numeric(df['Cyclone_cone_draft'], errors='coerce')\n",
    "df['Cyclone_Gas_Outlet_Temp'] = pd.to_numeric(df['Cyclone_Gas_Outlet_Temp'], errors='coerce')\n",
    "df['Cyclone_Inlet_Draft'] = pd.to_numeric(df['Cyclone_Inlet_Draft'], errors='coerce')\n",
    "\n",
    "#also coverting the time column from object to datetime will make it super easy for us to handle the data, for that we will use the pandas to_datetime() method\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df=df.set_index('time')\n",
    "#types after conversion\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f44bd5-b4d1-4fa3-9fd2-fdf0a1b6088f",
   "metadata": {},
   "source": [
    "With this our columns are now of float type with the help of the to_numeric() method of pandas. This method converted the numeric data to float type and non-numeric data to NaNs. And our time object is also of datetime type. Let's move on and see how many missing values are there in our data so that we can handle them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5e06b-78ba-4876-b4cc-b45fca3b5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's now see the NaN's (missing values) in our data set\n",
    "print(df.isna().sum())\n",
    "print(df.isna().sum().max())\n",
    "print(df.isna().sum().sum())\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "missingno.matrix(df, figsize = (30,10));\n",
    "plt.title(\"8195 missing values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a81cd",
   "metadata": {},
   "source": [
    "# Processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa689e7-32bd-48f8-9d5b-7a41de254f25",
   "metadata": {},
   "source": [
    "There are a total of 8195 missing values in our data with the maximum of them being in the Cyclone_Material_Temp column(1591 missing values). We cannot drop the rows or columns as it will result in large data loss which can lead to less accuracy of the model. With regards to the same, I'm going to impute the dataset values, with the help of the SimpleImputer() method of sklearn. I'm passing the strategy as mean to replace all the missing values with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e30ce8-677d-40d5-9ba3-034690cd5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "updated_df=df.copy()\n",
    "\n",
    "for col in updated_df.columns:\n",
    "    imp = SimpleImputer(strategy = 'mean')\n",
    "    updated_df[col] = imp.fit_transform(pd.DataFrame(updated_df[col]))\n",
    "updated_df.isnull().sum()\n",
    "updated_df=updated_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b6d49",
   "metadata": {},
   "source": [
    "# EDA(Exploratory data analysis)\n",
    "### Heatmap\n",
    "#### Heatmap is defined as a graphical representation of data using colors to visualize the value of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83f474-c937-4f54-b166-a075dea2b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = updated_df.corr()\n",
    "fig,ax=plt.subplots(figsize=(15,15))\n",
    "mask = np.zeros_like(corr, dtype='bool')\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr, mask=mask, cmap=sns.diverging_palette(220, 10, as_cmap=True), square=True, ax=ax, vmin = -1.0, vmax = 1.0, linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612edce",
   "metadata": {},
   "source": [
    "### Pairplot\n",
    "#### To plot multiple pairwise bivariate distributions in a dataset, you can use the pairplot() function. This shows the relationship for (n, 2) combination of variable in a DataFrame as a matrix of plots and the diagonal plots are the univariate plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb4ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(updated_df, plot_kws = {'alpha': 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2551fcf4",
   "metadata": {},
   "source": [
    "### Time series line plot\n",
    "#### Time series line plot helps to find the time period where the anomalies are present with the help of plotly. I've also added range slider and range selector buttons functionality which allows users to pan and zoom the X-axis while maintaining an overview of the chart and also helps to easily set the range of the x-axis respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc49ffe-44a8-493e-9891-b1a262bf2a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.line(updated_df, x='time', y='Cyclone_Inlet_Gas_Temp', title='Time Series with Rangeslider')\n",
    "\n",
    "fig.update_xaxes(\n",
    "    rangeslider_visible=True,\n",
    "    tickformatstops = [\n",
    "        dict(dtickrange=[None, 1000], value=\"%H:%M:%S.%L ms\"),\n",
    "        dict(dtickrange=[1000, 60000], value=\"%H:%M:%S s\"),\n",
    "        dict(dtickrange=[60000, 3600000], value=\"%H:%M m\"),\n",
    "        dict(dtickrange=[3600000, 86400000], value=\"%H:%M h\"),\n",
    "        dict(dtickrange=[86400000, 604800000], value=\"%e. %b d\"),\n",
    "       \n",
    "      \n",
    "    ],\n",
    "    \n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])\n",
    "    )\n",
    "    \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b8d5b4-9946-421d-a336-ac814d6991bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(updated_df, x='time', y='Cyclone_Material_Temp', title='Time Series with Rangeslider')\n",
    "\n",
    "fig.update_xaxes(\n",
    "    rangeslider_visible=True,\n",
    "    tickformatstops = [\n",
    "        dict(dtickrange=[None, 1000], value=\"%H:%M:%S.%L ms\"),\n",
    "        dict(dtickrange=[1000, 60000], value=\"%H:%M:%S s\"),\n",
    "        dict(dtickrange=[60000, 3600000], value=\"%H:%M m\"),\n",
    "        dict(dtickrange=[3600000, 86400000], value=\"%H:%M h\"),\n",
    "        dict(dtickrange=[86400000, 604800000], value=\"%e. %b d\"),\n",
    "       \n",
    "      \n",
    "    ],\n",
    "    \n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])\n",
    "    )\n",
    "    \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8550e4-acd7-4e6d-a20e-89167517f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(updated_df, x='time', y='Cyclone_Outlet_Gas_draft', title='Time Series with Rangeslider')\n",
    "\n",
    "fig.update_xaxes(\n",
    "    rangeslider_visible=True,\n",
    "    tickformatstops = [\n",
    "        dict(dtickrange=[None, 1000], value=\"%H:%M:%S.%L ms\"),\n",
    "        dict(dtickrange=[1000, 60000], value=\"%H:%M:%S s\"),\n",
    "        dict(dtickrange=[60000, 3600000], value=\"%H:%M m\"),\n",
    "        dict(dtickrange=[3600000, 86400000], value=\"%H:%M h\"),\n",
    "        dict(dtickrange=[86400000, 604800000], value=\"%e. %b d\"),\n",
    "       \n",
    "      \n",
    "    ],\n",
    "    \n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])\n",
    "    )\n",
    "    \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c431c4-37d2-4c86-b7be-59624b4f0507",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(updated_df, x='time', y='Cyclone_cone_draft', title='Time Series with Rangeslider')\n",
    "\n",
    "fig.update_xaxes(\n",
    "    rangeslider_visible=True,\n",
    "    tickformatstops = [\n",
    "        dict(dtickrange=[None, 1000], value=\"%H:%M:%S.%L ms\"),\n",
    "        dict(dtickrange=[1000, 60000], value=\"%H:%M:%S s\"),\n",
    "        dict(dtickrange=[60000, 3600000], value=\"%H:%M m\"),\n",
    "        dict(dtickrange=[3600000, 86400000], value=\"%H:%M h\"),\n",
    "        dict(dtickrange=[86400000, 604800000], value=\"%e. %b date\"),\n",
    "       \n",
    "      \n",
    "    ],\n",
    "    \n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])\n",
    "    )\n",
    "    \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b160299-7612-4821-904c-334b2c0c45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(updated_df, x='time', y='Cyclone_Gas_Outlet_Temp', title='Time Series with Rangeslider')\n",
    "\n",
    "fig.update_xaxes(\n",
    "    rangeslider_visible=True,\n",
    "    tickformatstops = [\n",
    "        dict(dtickrange=[None, 1000], value=\"%H:%M:%S.%L ms\"),\n",
    "        dict(dtickrange=[1000, 60000], value=\"%H:%M:%S s\"),\n",
    "        dict(dtickrange=[60000, 3600000], value=\"%H:%M m\"),\n",
    "        dict(dtickrange=[3600000, 86400000], value=\"%H:%M h\"),\n",
    "        dict(dtickrange=[86400000, 604800000], value=\"%e. %b date\"),\n",
    "       \n",
    "      \n",
    "    ],\n",
    "    \n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])\n",
    "    )\n",
    "    \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c5043d-8a3e-49d4-8175-2607ffb082ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(updated_df, x='time', y='Cyclone_Inlet_Draft', title='Time Series with Rangeslider')\n",
    "\n",
    "fig.update_xaxes(\n",
    "    rangeslider_visible=True,\n",
    "    tickformatstops = [\n",
    "        dict(dtickrange=[None, 1000], value=\"%H:%M:%S.%L ms\"),\n",
    "        dict(dtickrange=[1000, 60000], value=\"%H:%M:%S s\"),\n",
    "        dict(dtickrange=[60000, 3600000], value=\"%H:%M m\"),\n",
    "        dict(dtickrange=[3600000, 86400000], value=\"%H:%M h\"),\n",
    "        dict(dtickrange=[86400000, 604800000], value=\"%e. %b date\"),\n",
    "       \n",
    "      \n",
    "    ],\n",
    "    \n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])\n",
    "    )\n",
    "    \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ca96b",
   "metadata": {},
   "source": [
    "# Finding Anomalies/Abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea9cd2c",
   "metadata": {},
   "source": [
    "## 1. Box Plots\n",
    "#### When reviewing a box plot, an outlier is defined as a data point that is located outside the whiskers of the box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca9b98-fa2f-47d3-bcbf-6b08916455c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(updated_df, x=[\"Cyclone_Inlet_Draft\",'Cyclone_Gas_Outlet_Temp', 'Cyclone_cone_draft', 'Cyclone_Outlet_Gas_draft', 'Cyclone_Material_Temp'\n",
    "                           ,'Cyclone_Inlet_Gas_Temp'], \n",
    "             title=\"Box plot\",\n",
    "             hover_data=[\"time\"]) \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204eedc-cb03-47b5-9099-4d5576a75725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(40, 20))\n",
    "\n",
    "\n",
    "\n",
    "sns.distplot(ax=axes[0, 0], x=updated_df['Cyclone_Inlet_Draft'])\n",
    "axes[0,0].set_title('Cyclone_Inlet_Draft')\n",
    "sns.distplot(ax=axes[0, 1], x=updated_df['Cyclone_Gas_Outlet_Temp'])\n",
    "axes[0,1].set_title('Cyclone_Gas_Outlet_Temp')\n",
    "sns.distplot(ax=axes[0, 2], x=updated_df['Cyclone_cone_draft'])\n",
    "axes[0,2].set_title('Cyclone_cone_draft')\n",
    "sns.distplot(ax=axes[1, 0], x=updated_df['Cyclone_Outlet_Gas_draft'])\n",
    "axes[1,0].set_title('Cyclone_Outlet_Gas_draft')\n",
    "sns.distplot(ax=axes[1, 1], x=updated_df['Cyclone_Material_Temp'])\n",
    "axes[1,1].set_title('Cyclone_Material_Temp')\n",
    "sns.distplot(ax=axes[1, 2], x=updated_df['Cyclone_Inlet_Gas_Temp'])\n",
    "axes[1,2].set_title('Cyclone_Inlet_Gas_Temp')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3daa16",
   "metadata": {},
   "source": [
    "## 2. VAR Model  (Vector Auto-Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd5a42",
   "metadata": {},
   "source": [
    "#### For multivariate time series, algorithms like VAR, VARMA, VMA are more suitable as they contain more than on column with a timestamp associated. Because of the same reason, I'm gonna use the VAR model. First we will check if the data is stationary or not using the Augmented Dickey-Fuller Test. It gives us a p-value and if the p-value is less than the significance level then the data is stationary, or else the data is non-stationary. \n",
    "#### If the data turns out to be non-stationary we can convert it stationary through differencing, log transformations and seasonal decompositions. After coverting it to stationary we can proceed further with the VAR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd83ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adfuller_test(series, signif=0.05, name='', verbose=False):\n",
    "    \"\"\"Perform ADFuller to test for Stationarity of given series and print report\"\"\"\n",
    "    r = adfuller(series, autolag='AIC')\n",
    "    output = {'test_statistic':round(r[0], 4), 'pvalue':round(r[1], 4), 'n_lags':round(r[2], 4), 'n_obs':r[3]}\n",
    "    p_value = output['pvalue'] \n",
    "    def adjust(val, length= 6): return str(val).ljust(length)\n",
    "\n",
    "    # Print Summary\n",
    "    print(f'    Augmented Dickey-Fuller Test on \"{name}\"', \"\\n   \", '-'*47)\n",
    "    print(f' Null Hypothesis: Data has unit root. Non-Stationary.')\n",
    "    print(f' Significance Level    = {signif}')\n",
    "    print(f' Test Statistic        = {output[\"test_statistic\"]}')\n",
    "    print(f' No. Lags Chosen       = {output[\"n_lags\"]}')\n",
    "\n",
    "    for key,val in r[4].items():\n",
    "        print(f' Critical value {adjust(key)} = {round(val, 3)}')\n",
    "\n",
    "    if p_value <= signif:\n",
    "        print(f\" => P-Value = {p_value}. Rejecting Null Hypothesis.\")\n",
    "        print(f\" => Series is Stationary.\")\n",
    "    else:\n",
    "        print(f\" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.\")\n",
    "        print(f\" => Series is Non-Stationary.\")   \n",
    "for name, column in updated_df.iteritems():\n",
    "    adfuller_test(column, name=column.name)\n",
    "    print('\\n')     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df=updated_df.set_index('time')\n",
    "max_lag = 24\n",
    "var_model = VAR(updated_df)\n",
    "lag_results = var_model.select_order(max_lag)\n",
    "selected_lag = lag_results.aic\n",
    "print(selected_lag) # selected_lag = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_anomalies(squared_errors):\n",
    "    threshold = np.mean(squared_errors) + np.std(squared_errors)\n",
    "    predictions = (squared_errors >= threshold).astype(int)\n",
    "    return predictions, threshold\n",
    "var = VAR(updated_df)\n",
    "var_fitresults = var.fit(selected_lag)\n",
    "squared_errors = var_fitresults.resid.sum(axis=1) ** 2\n",
    "predictions, threshold = find_anomalies(squared_errors) # threshold = 7593.829254818655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384383db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean, stdev\n",
    "threshold = mean(squared_errors) + 3 * stdev(squared_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3402d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = updated_df.iloc[selected_lag:, :]\n",
    "data['Predictions'] = predictions.values\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd51d4e",
   "metadata": {},
   "source": [
    "#### According to the ouput we have 373104 normal data points and 4591 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Predictions'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014163c3",
   "metadata": {},
   "source": [
    "## 3. IQR\n",
    "#### To detect the outliers using this method, we define a new range between lower and upper, and any data point lying outside this range is considered as outlier and is accordingly dealt with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0890e12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the first and third quantiles and IQR of emissions_by_country\n",
    "columns= [\"Cyclone_Inlet_Draft\",'Cyclone_Gas_Outlet_Temp', 'Cyclone_cone_draft', 'Cyclone_Outlet_Gas_draft', 'Cyclone_Material_Temp'\n",
    " ,'Cyclone_Inlet_Gas_Temp']\n",
    "def iqr(col):\n",
    "    q1 = np.quantile(updated_df[col], 0.25)\n",
    "    q3 = np.quantile(updated_df[col], 0.75)\n",
    "    iqr = q3 - q1\n",
    "    # Calculate the lower and upper cutoffs for outliers\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    # Subset emissions_by_country to find outliers\n",
    "    outliers = updated_df[(updated_df[col] < lower) | (updated_df[col] > upper)]\n",
    "    print('Number of outliers in column', col, ': ', len(outliers[col]))\n",
    "iqr('Cyclone_Inlet_Draft')\n",
    "iqr('Cyclone_Gas_Outlet_Temp')\n",
    "iqr('Cyclone_cone_draft')\n",
    "iqr('Cyclone_Outlet_Gas_draft')\n",
    "iqr('Cyclone_Material_Temp')\n",
    "iqr('Cyclone_Inlet_Gas_Temp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
